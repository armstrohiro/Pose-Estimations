{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrGq2vcUJIRM5T6SIrjsxE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armstrohiro/Pose-Estimations/blob/main/mediapipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MediaPipe\n",
        "\n",
        "*   2/22日用\n",
        "*   関節座標データ\n",
        "\n"
      ],
      "metadata": {
        "id": "99VO1P9THLQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import pandas as pd\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "from IPython.display import IFrame\n",
        "from IPython.display import display\n",
        "!pip install youtube_dl\n",
        "import youtube_dl\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_pose = mp.solutions.pose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iifm2yqQ97MB",
        "outputId": "4ce27409-8043-408f-bae7-a4c877d3f4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.21 sounddevice-0.5.1\n",
            "Collecting youtube_dl\n",
            "  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube_dl\n",
            "Successfully installed youtube_dl-2021.12.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 動画ファイル読み込み（/content/に動画を入れる）\n",
        "input_filename = '00001.mp4'\n",
        "video_data = cv2.VideoCapture(input_filename)\n",
        "video_width = int(video_data.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "video_hight = int(video_data.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "print('FPS:',video_data.get(cv2.CAP_PROP_FPS))\n",
        "print('Dimensions:',video_width,video_hight)\n",
        "\n",
        "video_data_array = []\n",
        "\n",
        "print(\"VideoFrame:\",int(video_data.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "\n",
        "#ファイルが正常に読み込めている間ループする\n",
        "while video_data.isOpened():\n",
        "  #1フレームごとに読み込み\n",
        "  success, image = video_data.read()\n",
        "  if success:\n",
        "    #フレームの画像を追加\n",
        "    video_data_array.append(image)\n",
        "  else:\n",
        "    break\n",
        "video_data.release()\n",
        "print('Frames Read:',len(video_data_array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y4ZfeYK-AFT",
        "outputId": "2b8c90e3-0237-486b-c0f8-2880cd2dd412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPS: 0.0\n",
            "Dimensions: 0 0\n",
            "VideoFrame: 0\n",
            "Frames Read: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2/22日用\n",
        "\n",
        "\n",
        "1. 一つずつ\n",
        "\n"
      ],
      "metadata": {
        "id": "bH4518SU85Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import os\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# MediaPipe のセットアップ\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# 動画ファイルのパス（/content にある動画）\n",
        "input_filename = \"/content/videos/00001.mp4\"\n",
        "output_video_path = \"/content/output_00001.mp4\"  # 出力動画\n",
        "\n",
        "# 動画を読み込む\n",
        "video_data = cv2.VideoCapture(input_filename)\n",
        "video_width = int(video_data.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "video_height = int(video_data.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(video_data.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "print(f\"FPS: {fps}\")\n",
        "print(f\"Dimensions: {video_width} x {video_height}\")\n",
        "\n",
        "# 出力動画の設定\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (video_width, video_height))\n",
        "\n",
        "# MediaPipe Pose の初期化\n",
        "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
        "    while video_data.isOpened():\n",
        "        success, frame = video_data.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # BGR → RGB に変換（MediaPipe 用）\n",
        "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        image.flags.writeable = False\n",
        "\n",
        "        # 姿勢推定を実行\n",
        "        results = pose.process(image)\n",
        "\n",
        "        # RGB → BGR に戻す（OpenCV 用）\n",
        "        image.flags.writeable = True\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # 骨格を描画\n",
        "        if results.pose_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
        "                mp_drawing_styles.get_default_pose_landmarks_style()\n",
        "            )\n",
        "\n",
        "        # 処理したフレームを動画に保存\n",
        "        out.write(image)\n",
        "\n",
        "# 終了処理\n",
        "video_data.release()\n",
        "out.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "iqffsnXFB9NB",
        "outputId": "61ae54f8-418f-485b-8633-795d3c6ba94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPS: 30\n",
            "Dimensions: 640 x 360\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f47d91ac6990>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# 処理したフレームを動画に保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# 終了処理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "2. まとめて\n",
        "\n"
      ],
      "metadata": {
        "id": "XRNqDUcLEUSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#全部\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import os\n",
        "from IPython.display import display, HTML\n",
        "from base64 import b64encode\n",
        "from glob import glob\n",
        "\n",
        "# MediaPipe のセットアップ\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# 解析する動画を /content/ から自動取得\n",
        "input_videos = glob(\"/content/videos/*.mp4\")  # /content/ 内のすべての .mp4 ファイルを取得\n",
        "output_videos = []\n",
        "\n",
        "if not input_videos:\n",
        "    print(\"エラー: /content/videos に .mp4 ファイルが見つかりません！動画をアップロードしてください。\")\n",
        "else:\n",
        "    print(f\"{len(input_videos)} 本の動画を解析します: {input_videos}\")\n",
        "\n",
        "    # MediaPipe Pose を初期化\n",
        "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
        "        for input_filename in input_videos:\n",
        "            output_filename = input_filename.replace(\".mp4\", \"_output.mp4\")\n",
        "            output_videos.append(output_filename)\n",
        "\n",
        "            # 動画の読み込み\n",
        "            video_data = cv2.VideoCapture(input_filename)\n",
        "            video_width = int(video_data.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            video_height = int(video_data.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            fps = int(video_data.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "            print(f\"\\n解析中: {input_filename} (FPS: {fps}, サイズ: {video_width}x{video_height})\")\n",
        "\n",
        "            # 出力動画の設定\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_filename, fourcc, fps, (video_width, video_height))\n",
        "\n",
        "            while video_data.isOpened():\n",
        "                success, frame = video_data.read()\n",
        "                if not success:\n",
        "                    break\n",
        "\n",
        "                # BGR → RGB に変換（MediaPipe 用）\n",
        "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                image.flags.writeable = False\n",
        "\n",
        "                # 姿勢推定を実行\n",
        "                results = pose.process(image)\n",
        "\n",
        "                # RGB → BGR に戻す（OpenCV 用）\n",
        "                image.flags.writeable = True\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "                # 骨格を描画\n",
        "                if results.pose_landmarks:\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
        "                        mp_drawing_styles.get_default_pose_landmarks_style()\n",
        "                    )\n",
        "\n",
        "                # 処理したフレームを動画に保存\n",
        "                out.write(image)\n",
        "\n",
        "            # 終了処理\n",
        "            video_data.release()\n",
        "            out.release()\n",
        "            print(f\"保存完了: {output_filename}\")"
      ],
      "metadata": {
        "id": "QQznkmsuESjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#動画が再生されない\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('/content/processed_00001.mp4', 'rb').read()\n",
        "video_src = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "    <video width=\"432\" height=\"324\" controls>\n",
        "        <source type=\"video/mp4\" src=\"{video_src}\">\n",
        "    </video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "5OeXQUO7DfdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 関節座標出力コード"
      ],
      "metadata": {
        "id": "mutZZV458vYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 動画ファイル読み込み（/contentに動画を入れる）\n",
        "input_filename = '00015.mp4'\n",
        "video_data = cv2.VideoCapture(input_filename)\n",
        "video_width = int(video_data.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "video_hight = int(video_data.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "print('FPS:',video_data.get(cv2.CAP_PROP_FPS))\n",
        "print('Dimensions:',video_width,video_hight)\n",
        "\n",
        "video_data_array = []\n",
        "\n",
        "print(\"VideoFrame:\",int(video_data.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "\n",
        "#ファイルが正常に読み込めている間ループする\n",
        "while video_data.isOpened():\n",
        "  #1フレームごとに読み込み\n",
        "  success, image = video_data.read()\n",
        "  if success:\n",
        "    #フレームの画像を追加\n",
        "    video_data_array.append(image)\n",
        "  else:\n",
        "    break\n",
        "video_data.release()\n",
        "print('Frames Read:',len(video_data_array))"
      ],
      "metadata": {
        "id": "ueVlHItNAHo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with mp_pose.Pose(\n",
        "  static_image_mode=False,\n",
        "  model_complexity=2,\n",
        "  enable_segmentation=True,\n",
        "  min_detection_confidence=0.5) as pose:\n",
        "\n",
        "  #動画データをループ処理\n",
        "  for loop_counter,image_data in enumerate(video_data_array):\n",
        "\n",
        "    #画像解析\n",
        "    results = pose.process(cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB))\n",
        "    if not results.pose_landmarks:\n",
        "      continue\n",
        "\n",
        "    #解析結果を動画に描画\n",
        "    mp_drawing.draw_landmarks(\n",
        "        image_data,\n",
        "        results.pose_landmarks,\n",
        "        mp_pose.POSE_CONNECTIONS,\n",
        "        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
        "\n",
        "plt.imshow(cv2.cvtColor(video_data_array[0], cv2.COLOR_BGR2RGB))\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "sPPzS4_aAZ1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# 必要な関節を指定（右から左の順序にし、hipは手首と膝の間に挿入）\n",
        "target_landmarks = [\n",
        "    mp_pose.PoseLandmark.RIGHT_EYE, mp_pose.PoseLandmark.LEFT_EYE,\n",
        "    mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.LEFT_SHOULDER,\n",
        "    mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.LEFT_ELBOW,\n",
        "    mp_pose.PoseLandmark.RIGHT_WRIST, mp_pose.PoseLandmark.LEFT_WRIST,\n",
        "    # hipは手首と膝の間に挿入するため、ここには含めない\n",
        "    mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.LEFT_KNEE,\n",
        "    mp_pose.PoseLandmark.RIGHT_ANKLE, mp_pose.PoseLandmark.LEFT_ANKLE,\n",
        "    mp_pose.PoseLandmark.RIGHT_FOOT_INDEX, mp_pose.PoseLandmark.LEFT_FOOT_INDEX\n",
        "]\n",
        "\n",
        "# CSVファイルの列名を定義（右から左、hipは手首と膝の間に挿入）\n",
        "landmark_names = []\n",
        "for landmark in target_landmarks:\n",
        "    if landmark == mp_pose.PoseLandmark.RIGHT_WRIST:  # 右手首の後にhipを追加\n",
        "        landmark_names.append('hip_x')\n",
        "        landmark_names.append('hip_y')\n",
        "    landmark_names.append(f'{landmark.name}_x')\n",
        "    landmark_names.append(f'{landmark.name}_y')\n",
        "\n",
        "# CSVファイルの書き込み設定\n",
        "csv_filename = 'landmarks_00015.mp4.csv'\n",
        "with open(csv_filename, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    # ヘッダーを書き込み（フレーム番号と指定した関節の情報）\n",
        "    writer.writerow(['frame'] + landmark_names)\n",
        "\n",
        "    with mp_pose.Pose(\n",
        "        static_image_mode=False,\n",
        "        model_complexity=2,\n",
        "        enable_segmentation=True,\n",
        "        min_detection_confidence=0.5) as pose:\n",
        "\n",
        "        # 動画データをループ処理\n",
        "        for frame_number, image_data in enumerate(video_data_array):\n",
        "            # 画像の高さと幅を取得\n",
        "            height, width, _ = image_data.shape\n",
        "\n",
        "            # 画像解析\n",
        "            results = pose.process(cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB))\n",
        "            if not results.pose_landmarks:\n",
        "                continue\n",
        "\n",
        "            # 各指定したランドマークの座標を抽出\n",
        "            row = [frame_number]  # フレーム番号を追加\n",
        "            for landmark in target_landmarks:\n",
        "                # 手首の後にhipを追加\n",
        "                if landmark == mp_pose.PoseLandmark.RIGHT_WRIST:\n",
        "                    left_hip = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP]\n",
        "                    right_hip = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP]\n",
        "                    hip_x = (left_hip.x + right_hip.x) / 2 * width\n",
        "                    hip_y = (left_hip.y + right_hip.y) / 2 * height\n",
        "                    row.extend([hip_x, hip_y])\n",
        "\n",
        "                # 各関節の x, y 座標を取得し、ピクセル単位に変換\n",
        "                lm = results.pose_landmarks.landmark[landmark]\n",
        "                x_px = lm.x * width         # x座標をピクセル単位に変換（小数）\n",
        "                y_px = lm.y * height        # y座標をピクセル単位に変換（小数）\n",
        "                row.extend([x_px, y_px])    # x, yを交互に追加\n",
        "\n",
        "            # CSVファイルに行を書き込み\n",
        "            writer.writerow(row)\n",
        "\n",
        "print(f'Specified landmark coordinates saved to {csv_filename}')\n"
      ],
      "metadata": {
        "id": "VpZipv09GoAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#全部まとめて\n",
        "import csv\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# 必要な関節を指定（右から左の順序にし、hipは手首と膝の間に挿入）\n",
        "target_landmarks = [\n",
        "    mp_pose.PoseLandmark.RIGHT_EYE, mp_pose.PoseLandmark.LEFT_EYE,\n",
        "    mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.LEFT_SHOULDER,\n",
        "    mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.LEFT_ELBOW,\n",
        "    mp_pose.PoseLandmark.RIGHT_WRIST, mp_pose.PoseLandmark.LEFT_WRIST,\n",
        "    # hipは手首と膝の間に挿入するため、ここには含めない\n",
        "    mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.LEFT_KNEE,\n",
        "    mp_pose.PoseLandmark.RIGHT_ANKLE, mp_pose.PoseLandmark.LEFT_ANKLE,\n",
        "    mp_pose.PoseLandmark.RIGHT_FOOT_INDEX, mp_pose.PoseLandmark.LEFT_FOOT_INDEX\n",
        "]\n",
        "\n",
        "# CSVファイルの列名を定義（右から左、hipは手首と膝の間に挿入）\n",
        "landmark_names = []\n",
        "for landmark in target_landmarks:\n",
        "    if landmark == mp_pose.PoseLandmark.RIGHT_WRIST:  # 右手首の後にhipを追加\n",
        "        landmark_names.append('hip_x')\n",
        "        landmark_names.append('hip_y')\n",
        "    landmark_names.append(f'{landmark.name}_x')\n",
        "    landmark_names.append(f'{landmark.name}_y')\n",
        "\n",
        "# MediaPipeの姿勢推定設定\n",
        "with mp_pose.Pose(\n",
        "    static_image_mode=False,\n",
        "    model_complexity=2,\n",
        "    enable_segmentation=True,\n",
        "    min_detection_confidence=0.5) as pose:\n",
        "\n",
        "    # 00001.mp4から00015.mp4までを処理\n",
        "    for video_num in range(1, 14):\n",
        "        input_filename = f'{video_num:05}.mp4'\n",
        "        video_data = cv2.VideoCapture(input_filename)\n",
        "\n",
        "        # 動画が存在しない場合はスキップ\n",
        "        if not video_data.isOpened():\n",
        "            print(f\"Cannot open video file: {input_filename}\")\n",
        "            continue\n",
        "\n",
        "        # 動画の出力用CSVファイル名\n",
        "        csv_filename = f'landmarks_{input_filename}.csv'\n",
        "        with open(csv_filename, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            # ヘッダーを書き込み（フレーム番号と指定した関節の情報）\n",
        "            writer.writerow(['frame'] + landmark_names)\n",
        "\n",
        "            frame_number = 0\n",
        "            while video_data.isOpened():\n",
        "                # 各フレームを読み込み\n",
        "                success, image_data = video_data.read()\n",
        "                if not success:\n",
        "                    break\n",
        "\n",
        "                # 画像の高さと幅を取得\n",
        "                height, width, _ = image_data.shape\n",
        "\n",
        "                # 画像解析\n",
        "                results = pose.process(cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB))\n",
        "                if not results.pose_landmarks:\n",
        "                    frame_number += 1\n",
        "                    continue\n",
        "\n",
        "                # 各指定したランドマークの座標を抽出\n",
        "                row = [frame_number]  # フレーム番号を追加\n",
        "                for landmark in target_landmarks:\n",
        "                    # 手首の後にhipを追加\n",
        "                    if landmark == mp_pose.PoseLandmark.RIGHT_WRIST:\n",
        "                        left_hip = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP]\n",
        "                        right_hip = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP]\n",
        "                        hip_x = (left_hip.x + right_hip.x) / 2 * width\n",
        "                        hip_y = (left_hip.y + right_hip.y) / 2 * height\n",
        "                        row.extend([hip_x, hip_y])\n",
        "\n",
        "                    # 各関節の x, y 座標を取得し、ピクセル単位に変換\n",
        "                    lm = results.pose_landmarks.landmark[landmark]\n",
        "                    x_px = lm.x * width         # x座標をピクセル単位に変換（小数）\n",
        "                    y_px = lm.y * height        # y座標をピクセル単位に変換（小数）\n",
        "                    row.extend([x_px, y_px])    # x, yを交互に追加\n",
        "\n",
        "                # CSVファイルに行を書き込み\n",
        "                writer.writerow(row)\n",
        "                frame_number += 1\n",
        "\n",
        "        video_data.release()\n",
        "        print(f'Specified landmark coordinates saved to {csv_filename}')\n"
      ],
      "metadata": {
        "id": "ycVOY6MLHvwG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}